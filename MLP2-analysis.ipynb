{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23147ccd-6cff-4b42-a5e7-b83ef147b8bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this code to compute TP,FP,TN,FN produced by the classifier on all folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b12be9-c454-449d-a70f-9309970ec162",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from datetime import datetime\n",
    "from tqdm.auto import tqdm\n",
    "import math\n",
    "import sys\n",
    "import os\n",
    "import json\n",
    "import evaluate\n",
    "import numpy as np\n",
    "from simpletransformers.language_representation import RepresentationModel\n",
    "from transformers import AutoTokenizer,AutoModelForQuestionAnswering,pipeline,AutoModelForSequenceClassification\n",
    "from torch.utils.data import TensorDataset, RandomSampler,DataLoader\n",
    "from sklearn.metrics import classification_report\n",
    "import general_util as gu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80d53640-2585-48a0-a515-1a5f0ea03fa8",
   "metadata": {},
   "source": [
    "Test available GPUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b68d1421-9829-4578-b3bc-c3dc3d781343",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.cuda.device_count())\n",
    "gpu_ids = [gpu_id for gpu_id in range(torch.cuda.device_count())]\n",
    "print(gpu_ids)\n",
    "device = torch.device(f'cuda:{gpu_ids[0]}')\n",
    "torch.cuda.set_device(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b321f84c-2cf4-41dd-a02f-8d8977362637",
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "bert_mean_embedding = RepresentationModel(\n",
    "            model_type=\"bert\", model_name=\"bert-base-uncased\",\n",
    "            use_cuda=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "240b0238-6446-4930-9154-c98d0b8b1f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self,hidden_size1, hidden_size2, output_dim, dropout,gamma,alpha):\n",
    "        super().__init__()\n",
    "\n",
    "        self.num_classes = output_dim\n",
    "        self.gamma = gamma\n",
    "        self.alpha = alpha\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(hidden_size1, hidden_size2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_size2, self.num_classes),\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, x,labels=None):\n",
    "\n",
    "        logits = self.classifier(x)\n",
    "\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            # if labels is not None:\n",
    "            assert self.num_classes == 2, f'Expected 2 labels but found {self.num_labels}'\n",
    "            if self.alpha != None:\n",
    "                alpha_tensor = torch.Tensor([self.alpha, 1 - self.alpha])\n",
    "                loss_fct = F.cross_entropy(logits.view(-1, self.num_classes), labels.view(-1), weight=alpha_tensor)\n",
    "            else:\n",
    "                loss_fct = F.cross_entropy(logits.view(-1, self.num_classes), labels.view(-1))\n",
    "\n",
    "            pt = torch.exp(-loss_fct)\n",
    "            loss = (((1 - pt) ** self.gamma * loss_fct)+loss_fct)/2\n",
    "\n",
    "        return loss,torch.sigmoid(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec083bce-039c-4b29-b5b0-d42bf06bbc81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_val_data(fold):\n",
    "    dataset = gu.load_data(fold)\n",
    "\n",
    "    val_data = dataset[\"validation\"]#.select(range(10))\n",
    "\n",
    "    contexts = []\n",
    "    labels = []\n",
    "    ids = []\n",
    "    for context, label,id in zip(val_data['context'],val_data['label'],val_data[\"id\"]):\n",
    "        contexts.append(context)\n",
    "        labels.append(label)\n",
    "        ids.append(id)\n",
    "\n",
    "    return contexts, labels,ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1038abe7-3975-4acd-aa1b-a62048725c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_iter(x,y,ids, batch_size, shuffle=False):\n",
    "    batch_num = math.ceil(len(x) / batch_size)\n",
    "    index_array = list(range(len(y)))\n",
    "\n",
    "    if shuffle:\n",
    "        np.random.shuffle(index_array)\n",
    "\n",
    "    for i in range(batch_num):\n",
    "        indices = index_array[i * batch_size: (i + 1) * batch_size]\n",
    "        contexts = [x[idx] for idx in indices]\n",
    "        labels = [y[idx] for idx in indices]\n",
    "        identifiers = [ids[idx] for idx in indices]\n",
    "\n",
    "        yield contexts, labels,identifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16acf650-a8ef-4854-9739-939568379383",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this function receives (text,label,id) lists, get the bert embedding for the text and creates a dataloader for the text,label,id triple\n",
    "def get_dataloader(x,y,id,batch_size):\n",
    "    #get embedding\n",
    "    x_train= bert_mean_embedding.encode_sentences(x,combine_strategy=\"mean\")\n",
    "    #convert to tensors\n",
    "    x= torch.Tensor(x_train)\n",
    "    y = torch.LongTensor(y)\n",
    "    id = [int(z) for z in id]\n",
    "    id = torch.LongTensor(id)\n",
    "    #create dataloader\n",
    "    tmp_DataSet = TensorDataset(x, y,id)\n",
    "    tmp_Sampler = RandomSampler(tmp_DataSet)\n",
    "    _DataLoader = DataLoader(tmp_DataSet, batch_size=batch_size, sampler=tmp_Sampler)\n",
    "    \n",
    "    return _DataLoader\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "872a261c-fbba-4425-b82f-863858325a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_dict_to_txt_file(dic,file_name):    \n",
    "    with open(f'{file_name}.txt', 'w') as convert_file:\n",
    "        convert_file.write(json.dumps(dic))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f09334fa-e788-46a3-bb32-d3db65c97cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_dict_from_txt_file(file_name):\n",
    "   # reading the data from the file\n",
    "    with open(f'{file_name}.txt') as f:\n",
    "        data = f.read()\n",
    "            \n",
    "    # reconstructing the data as a dictionary\n",
    "    js = json.loads(data)\n",
    "\n",
    "    return eval(str(js))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f0263f-64e8-48f8-967b-57786987f989",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_statistics_and_return_cls_dictionary(all_ids,all_preds,all_labels,all_preds_probabilites):\n",
    "    \n",
    "    fold_classification_results = {}\n",
    "    tp,tn,fp,fn = 0,0,0,0\n",
    "    # id is the context id, p is the predicted label and l is the ground truth label\n",
    "    for id,p,l,probs  in zip(all_ids,all_preds,all_labels,all_preds_probabilites):\n",
    "        #add item to the result dictionary\n",
    "        cur_id = id#.item()\n",
    "        if str(cur_id) in fold_classification_results.keys():\n",
    "            print(f\"Context with id {cur_id} is duplicated\\n\")\n",
    "        fold_classification_results[str(cur_id)] =(p,probs)\n",
    "        \n",
    "        if l==1 and p==1:\n",
    "            tp+=1\n",
    "        elif l==1 and p==0:\n",
    "            fn+=1\n",
    "        elif l==0 and p==1:\n",
    "            fp+=1\n",
    "        elif l==0 and p==0:\n",
    "            tn+=1\n",
    "    \n",
    "    print(f\"True Positive:{tp}\\nTrue Negative: {tn}\\nFalse Positive: {fp}\\nFalse Negative: {fn}\\n\")\n",
    "    return fold_classification_results\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c21681c-529c-49cb-bcea-dc8a5a1aabbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "old_stdout = sys.stdout\n",
    "sys.stdout= open(\"cls_preds_as_probs_wiht_bert.txt\",\"w\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f88ea5-a999-4bb8-a71a-befd6dcc6895",
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply the mlp-2 filter on the contexts\n",
    "lr = 5e-5\n",
    "batch_size = 100\n",
    "dropout_keep_prob = 0.5\n",
    "num_classes = 2\n",
    "\n",
    "hidden_size1 = 768\n",
    "hidden_size2 = 1024\n",
    "num_epochs = 5\n",
    "\n",
    "\n",
    "cls_model = MLP(hidden_size1, hidden_size2, num_classes, dropout_keep_prob,alpha=0.10,gamma=4)\n",
    "\n",
    "for fold_id in [0,1,2,3,4]:\n",
    "    \n",
    "    print(f\"\\n********************fold{fold_id}*******************\\n\")\n",
    "    #print(f\"this file uses no_answer_threshold: {thresholds[fold_id]}\")\n",
    "\n",
    "    x_val,y_val,ids = get_val_data(fold_id)\n",
    "    val_dataloader = get_dataloader(x_val,y_val,ids,batch_size)\n",
    "    cls_model.load_state_dict(torch.load(f'fresh_filter/saved_weights_{fold_id}.pt'))\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    epoch_recall = 0\n",
    "    epoch_f1 = 0\n",
    "    batch_num = len(val_dataloader) # number of batches\n",
    "    cls_model.eval()\n",
    "\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    all_ids = []\n",
    "    all_preds_probabilites = []\n",
    "    with torch.no_grad():\n",
    "        for step, batch in enumerate(tqdm(val_dataloader)):\n",
    "            loss,predictions = cls_model(batch[0],batch[1])\n",
    "            cls_output = torch.argmax(predictions,dim=1)\n",
    "            out= predictions[:,0]\n",
    "\n",
    "            all_labels.extend(batch[1])\n",
    "            all_preds.extend(cls_output.tolist())\n",
    "            all_preds_probabilites.extend(out.tolist())\n",
    "            \n",
    "            all_ids.extend(batch[2])\n",
    "            \n",
    "\n",
    "    print(classification_report(all_labels, all_preds))\n",
    "    \n",
    "    #compute fold statistics and get fold classification results\n",
    "    cls_dict=compute_statistics_and_return_cls_dictionary(all_ids,all_preds,all_labels,all_preds_probabilites)\n",
    "    \n",
    "    #save fold calssification results\n",
    "    save_dict_to_txt_file(cls_dict,f\"fresh_filter/fold_cls_results_final/fold{fold_id}\")\n",
    "    \n",
    "    #read_dict_to_txt_file(f\"fresh_filter/fold_cls_results/fold{fold_id}\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee581e6-677c-460b-b44b-a359e20ca82e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply bert filter on the contexts\n",
    "batch_size = 128\n",
    "num_classes = 2\n",
    "max_len = 500\n",
    "global tokenizer\n",
    "model_checkpoint = \"best_acc_filter/\"\n",
    "\n",
    "\n",
    "for fold_id in [0,1,2,3,4]:\n",
    "    \n",
    "    print(f\"\\n********************fold{fold_id}*******************\\n\")\n",
    "    #print(f\"this file uses no_answer_threshold: {thresholds[fold_id]}\")\n",
    "    \n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_checkpoint+ \"exp_\"+str(fold_id))\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_checkpoint+\"exp_\"+str(fold_id),num_labels=num_classes).to(device)\n",
    "        \n",
    "    model.eval()\n",
    "    \n",
    "    x_val,y_val,ids = get_val_data(fold_id)\n",
    "    #val_dataloader = get_val_dataloader(x_val,y_val,ids,batch_size)\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    epoch_recall = 0\n",
    "    epoch_f1 = 0\n",
    "    #batch_num = len(val_dataloader) # number of batches\n",
    "\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    all_ids = []\n",
    "    all_preds_probabilites = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for x,y,ids in batch_iter(x_val,y_val,ids, batch_size, shuffle=False):\n",
    "\n",
    "            cur_x = tokenizer(x,truncation=True,padding=True,return_tensors=\"pt\").to(device)\n",
    "            cur_y= torch.LongTensor(y).to(device)\n",
    "            \n",
    "            outputs = model(**cur_x,labels=cur_y)\n",
    "            #consider the logits\n",
    "            logits = outputs.logits\n",
    "            \n",
    "            #transfer logits to probabilities\n",
    "            probabilities = F.softmax(logits, dim=-1)\n",
    "            \n",
    "            #use probabilites to predict the label\n",
    "            cls_output = torch.argmax(probabilities,dim=1)\n",
    "            \n",
    "            #consider the no-dataset probabilities for each context\n",
    "            out= probabilities[:,0]\n",
    "\n",
    "            all_labels.extend(y)\n",
    "            all_preds.extend(cls_output.cpu().numpy().tolist())\n",
    "            all_preds_probabilites.extend(out.cpu().numpy().tolist())\n",
    "            \n",
    "            all_ids.extend(ids)\n",
    "   \n",
    "\n",
    "    print(classification_report(all_labels, all_preds))\n",
    "    \n",
    "    #compute fold statistics and get fold classification results\n",
    "    cls_dict=compute_statistics_and_return_cls_dictionary(all_ids,all_preds,all_labels,all_preds_probabilites)\n",
    "    \n",
    "    #save fold calssification results\n",
    "    save_dict_to_txt_file(cls_dict,f\"{model_checkpoint}result_fold{fold_id}\")\n",
    "    \n",
    "    #read_dict_to_txt_file(f\"fresh_filter/fold_cls_results/fold{fold_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe915d43-94b9-4e33-8460-97c52e00e562",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
